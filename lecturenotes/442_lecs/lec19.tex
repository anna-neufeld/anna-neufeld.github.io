\section{Thursday, April 24: Safety, Ethics, and Explainability}

I have no notes to post for today because we have our guest speakers! I will post their slides on GLOW after their talks. 

The main things I hope you got from this lecture are:

\begin{itemize}
\item There are many explainability techniques that can be used to understand the predictions of a black box model. 
\item It is possible to ``trick" a black-box model with an adversarial attack. For example, Blake showed us the example where we can trick a self-driving car into thinking that a stop sign is actually a ``40mph" sign by imperceptibly changing a few pictures. This type of vulnerability is really bad!
\item We need to be able to probe models to look for possible vulnerabilities. This is red-teaming. Who should be responsible for this type of careful auditing for real-world models? 	
\end{itemize}

You should all let me know what else you learned from this guest lecture, and what else you think the key takeaways here. 


\section{Monday, April 28: No class}

Sorry about the schedule change!

\section{Thursday, May 1: Class discussion on ethics, explainability, and fairness}

You all submitted great discussion questions and we had a great discussion! No formal lectures notes for this unit. Here are some things that we discussed that I hope you will all keep in mind in your future statistical careers.

\begin{itemize}
\item What can go-wrong when black-box prediction models are employed for high-stakes decision making? One example we saw was recidivism prediction (used to create sentencing decisions). You all also looked up your own examples, and found examples in hiring, college admissions, medical resource allocation, and facial recognition.
\item Who should be held accountable when ethical issues arise in the use of prediction models? The creator of the model? The person using the model? The local government wherever it is being used? Outside academics who conduct audits of the models? We saw that a lot can go wrong when no one is specifically held responsible! 
\item Are their settings where it is ``good" to use black-box prediction models because they are so accurate, etc? You all mostly think yes; just maybe not in these high-stakes settings where an individual person is affected and would like to be able to argue with their results, etc. 
\item How do we define fairness? (This could be a whole class).
\item Is explainability enough, or do we need true interpretability? (Rudin thinks explainability is not enough). 
\end{itemize}

Think about any other takeaways you have from your reading! 







